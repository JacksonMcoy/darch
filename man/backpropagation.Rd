% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/backpropagation.R
\name{backpropagation}
\alias{backpropagation}
\title{Backpropagation learning function}
\usage{
backpropagation(darch, trainData, targetData,
  bp.learnRate = getDarchParam(".bp.learnRate", rep(1, times =
  length(darch@layers))),
  bp.learnRateScale = getDarchParam("bp.learnRateScale", 1, darch),
  nesterovMomentum = getDarchParam("darch.nesterovMomentum", T, darch),
  dropout = getDarchParam(".darch.dropout", rep(0, times =
  length(darch@layers) + 1), darch),
  dropConnect = getDarchParam("darch.dropout.dropConnect", F, darch),
  matMult = getDarchParam("matMult", `\%*\%`, darch),
  debugMode = getDarchParam("debug", F, darch), ...)
}
\arguments{
\item{darch}{An instance of the class \code{\linkS4class{DArch}}.}

\item{trainData}{The data for training.}

\item{targetData}{The targets for the data.}

\item{bp.learnRate}{Learning rates for backpropagation, length is either one
or the same as the number of layers when using different learning rates
for each layer.}

\item{bp.learnRateScale}{The learn rate is multiplied by this value after
each epoch.}

\item{nesterovMomentum}{See \code{darch.nesterovMomentum} parameter of
\code{\link{darch}}.}

\item{dropout}{See \code{darch.dropout} parameter of
\code{\link{darch}}.}

\item{dropConnect}{See \code{darch.dropout.dropConnect} parameter of
\code{\link{darch}}.}

\item{matMult}{Matrix multiplication function, internal parameter.}

\item{debugMode}{Whether debug mode is enabled, internal parameter.}

\item{...}{Further parameters.}
}
\value{
The trained deep architecture
}
\description{
This function provides the backpropagation algorithm for deep architectures.
}
\details{
The function is getting the learning parameters from the provided
\code{\linkS4class{DArch}} object. It uses the attributes
\code{initialMomentum}, \code{finalMomentum} and \code{momentumRampLength}
for the calculation of the new weights with momentum. The parameter
\code{bp.learnRate} will be used to update the weights.
}
\references{
Rumelhart, D., G. E. Hinton, R. J. Williams, Learning
  representations by backpropagating errors, Nature 323, S. 533-536, DOI:
  10.1038/323533a0, 1986.
}
\seealso{
\code{\linkS4class{DArch}}, \code{\link{rpropagation}},
  \code{\link{minimizeAutoencoder}} \code{\link{minimizeClassifier}}
  \code{\link{minimizeClassifier}}

Other fine-tuning functions: \code{\link{rpropagation}}
}

