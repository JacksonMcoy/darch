% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/examples.R
\name{example.maxout}
\alias{example.maxout}
\title{darch MNIST example, using both dropout and maxout.}
\description{
darch MNIST example, using both dropout and maxout.
}
\details{
Since maxout requires linear activations, all activations have been changed
accordingly. You will notice an overall drop in convergence speed compared to
the basic MNIST example, but also a smaller difference between the accuracies
on the training and validation set.

We use a bigger second layer (400 neurons) and a maxout pool size of 4, which
will effectively result in 100 outputs for this layer, the same as in the
basic MNIST example.

A higher number of fine-tuning epochs and a bigger DBN is necessary to
observe the true potential of dropout and maxout.
}
\seealso{
Other darch.examples: \code{\link{example.iris}};
  \code{\link{example.mnist}};
  \code{\link{example.xorNominal}};
  \code{\link{example.xor}}
}

